import os
import shutil
import pathlib
import itertools
import pandas as pd
import pycolmap

# ğŸ“Œ COLMAP ì‘ì—… ê²½ë¡œ ì„¤ì •
output_path = pathlib.Path("output")  # COLMAP ê²°ê³¼ ì €ì¥ í´ë”
match_db_path = output_path / "match_db"  # Feature Matching ê²°ê³¼ í´ë”
sparse_output_path = output_path / "sparse"  # Sparse Reconstruction ê²°ê³¼ ì €ì¥ í´ë”
if sparse_output_path.exists():
    shutil.rmtree(sparse_output_path)
sparse_output_path.mkdir(exist_ok=True)

# âœ… ì‚¬ìš©ëœ ë°ì´í„°ë² ì´ìŠ¤ (Feature Matching í›„ ê²°ê³¼)
database_path = match_db_path / "matched_database_0.db"
image_dir = pathlib.Path("images")  # COLMAPì—ì„œ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í´ë”

# âœ… 1ï¸âƒ£ **íŠœë‹í•  ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±**
min_num_matches_list = [13, 15, 17]  # âœ… ìµœì†Œ ë§¤ì¹­ ê°œìˆ˜
min_model_size_list = [11, 13, 15, 19]  # âœ… ìµœì†Œ ë“±ë¡ ì´ë¯¸ì§€ ê°œìˆ˜
init_num_trials_list = [500, 1000, 1500]  # âœ… Reconstruction ì´ˆê¸°í™” ì‹œë„ íšŸìˆ˜

param_list = list(itertools.product(min_num_matches_list, min_model_size_list, init_num_trials_list))

# âœ… 2ï¸âƒ£ **Sparse Reconstruction ì‹¤í–‰ í•¨ìˆ˜**
def run_sparse_reconstruction(i, min_num_matches, min_model_size, init_num_trials):
    exp_sparse_output_path = sparse_output_path / f"sparse_{i}"  # ê°œë³„ ì‹¤í—˜ í´ë” ìƒì„±
    exp_sparse_output_path.mkdir(exist_ok=True)

    print(f"ğŸ” [{i+1}] Sparse Reconstruction: min_matches={min_num_matches}, min_model_size={min_model_size}, init_trials={init_num_trials}")

    # âœ… Reconstruction ì˜µì…˜ ì„¤ì •
    options = pycolmap.IncrementalPipelineOptions()
    options.num_threads = 8  # ë‹¤ì¤‘ ìŠ¤ë ˆë“œ ì„¤ì •
    options.ba_local_max_num_iterations = 50  # Local Bundle Adjustment ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    options.ba_global_max_num_iterations = 100  # Global Bundle Adjustment ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    options.min_num_matches = min_num_matches  # âœ… ìµœì†Œ ë§¤ì¹­ ê°œìˆ˜
    options.min_model_size = min_model_size  # âœ… ìµœì†Œ ë“±ë¡ ì´ë¯¸ì§€ ê°œìˆ˜
    options.init_num_trials = init_num_trials  # âœ… ì´ˆê¸° ì´ë¯¸ì§€ í˜ì–´ ì„ íƒ ì‹œë„ íšŸìˆ˜
    options.multiple_models = False  # âœ… ë‹¨ì¼ ëª¨ë¸ Reconstruction ìˆ˜í–‰

    try:
        # âœ… Sparse Reconstruction ì‹¤í–‰
        reconstruction = pycolmap.incremental_mapping(
            database_path=str(database_path),
            image_path=str(image_dir),
            output_path=str(exp_sparse_output_path),
            options=options
        )

        num_images_registered = max([reconstruction[i].num_reg_images() for i in reconstruction])

        # âœ… `cameras.bin` íŒŒì¼ í¬ê¸° í™•ì¸
        camera_bin_path = exp_sparse_output_path / "sparse/0/cameras.bin"
        camera_bin_size = os.path.getsize(camera_bin_path) if camera_bin_path.exists() else 0

        for model_id, model in reconstruction.items():
            print(f"Model {model_id}: ë“±ë¡ëœ ì´ë¯¸ì§€ ê°œìˆ˜ = {model.num_reg_images()}")

        print(f"âœ… Reconstruction ì™„ë£Œ! {num_images_registered}ê°œ ì´ë¯¸ì§€ ë“±ë¡ë¨. ì €ì¥ ê²½ë¡œ: {exp_sparse_output_path}")

    except Exception as e:
        print(f"âŒ Reconstruction ì‹¤íŒ¨: {e}")
        num_images_registered = 0
        camera_bin_size = 0

    return [exp_sparse_output_path, min_num_matches, min_model_size, init_num_trials, num_images_registered, camera_bin_size]

# âœ… 3ï¸âƒ£ **ëª¨ë“  ì¡°í•© ì‹¤í–‰**
results = []
for i, params in enumerate(param_list):
    results.append(run_sparse_reconstruction(i, *params))

# âœ… 4ï¸âƒ£ **ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥**
results_df = pd.DataFrame(results, columns=["output_path", "min_num_matches", "min_model_size", "init_num_trials", "num_images_registered", "camera_bin_size"])
results_df.to_csv(sparse_output_path / "sparse_results.csv", index=False)

print("âœ… ëª¨ë“  Sparse Reconstruction ì‹¤í—˜ ì™„ë£Œ! ê²°ê³¼ CSV ì €ì¥ë¨.")
