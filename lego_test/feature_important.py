import os
import shutil
import pathlib
import itertools
import pandas as pd
import pycolmap
import multiprocessing
import sqlite3

# ğŸ“Œ COLMAP ê´€ë ¨ ê²½ë¡œ ì„¤ì •
image_dir = pathlib.Path("train")  # ë°°ê²½ì´ ì œê±°ëœ ì´ë¯¸ì§€ í´ë”
output_path = pathlib.Path("output")  # COLMAP ê²°ê³¼ ì €ì¥ í´ë”

# âœ… ë¡œê·¸ í´ë” ì„¤ì •
log_dir = pathlib.Path("log")
log_dir.mkdir(parents=True, exist_ok=True)

# âœ… CSV íŒŒì¼ ì„¤ì •
feature_csv = output_path / "feature_analysis.csv"

# âœ… SIFT ë³€ìˆ˜ ì¡°í•© (íŠ¹ì´ì  ê²€ì¶œ)
# num_octaves_list = [6 + 1 * x for x in range(4)]
# edge_threshold_list = [5 + 2 * x for x in range(6)]
# peak_threshold_list = [0.005 - 0.0009 * x for x in range(5)]

num_octaves_list = [6]
edge_threshold_list = [15]
peak_threshold_list = [0.0014]

# âœ… íŠ¹ì´ì  ê²€ì¶œ ì‹¤í–‰ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬)
def extract_features(i, num_octaves, edge_threshold, peak_threshold):
    temp_db = output_path / f"database_{i}.db"
    print(f"ğŸ” [{i+1}] Running SIFT extraction: num_octaves={num_octaves}, edge_threshold={edge_threshold}, peak_threshold={peak_threshold}")

    try:
        # âœ… Feature Extraction ì‹¤í–‰
        pycolmap.extract_features(
            database_path=str(temp_db),
            image_path=str(image_dir),
            camera_model="SIMPLE_RADIAL",
            sift_options=pycolmap.SiftExtractionOptions(
                num_threads=8,
                max_num_features=8192,
                peak_threshold=peak_threshold,
                num_octaves=num_octaves,
                edge_threshold=edge_threshold,
            ),
            device=pycolmap.Device("cpu")
        )

    except Exception as e:
        print(f"âŒ Error in feature extraction {i+1}: {e}")

    return temp_db

# âœ… ë©€í‹°í”„ë¡œì„¸ì‹± ì‹¤í–‰
if __name__ == "__main__":
    
    # âœ… ê¸°ì¡´ output í´ë” ì‚­ì œ í›„ ìƒì„±
    if output_path.exists():
        shutil.rmtree(output_path)
    output_path.mkdir(exist_ok=True)
    
    param_list = list(itertools.product(num_octaves_list, edge_threshold_list, peak_threshold_list))

    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì • (CPU ê°œìˆ˜ë§Œí¼ ë³‘ë ¬ ì‹¤í–‰)
    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        db_paths = pool.starmap(extract_features, [(i, *params) for i, params in enumerate(param_list)])

    # âœ… DB ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° íŠ¹ì´ì  ê°œìˆ˜ í‰ê·  ê³„ì‚°
    itteration = 0
    feature_data = []
    for db_path in db_paths:
        if not os.path.exists(db_path):
            print(f"âš ï¸ Warning: Database {db_path} not found, skipping...")
            continue

        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()

            # âœ… WAL ëª¨ë“œ í™œì„±í™” (ë™ì‹œ ì ‘ê·¼ ë¬¸ì œ í•´ê²°)
            cursor.execute("PRAGMA journal_mode=WAL;")

            # âœ… ëª¨ë“  keypoints ë°ì´í„° ë¡œë“œ
            df_keypoints = pd.read_sql_query("SELECT * FROM keypoints;", conn)

            # âœ… keypoints í…Œì´ë¸”ì˜ rows ê°’ë“¤ì˜ í‰ê·  ê³„ì‚°
            average_keypoints = df_keypoints["rows"].sum() / df_keypoints["image_id"].nunique()

            # âœ… matches í…Œì´ë¸”ì˜ ì „ì²´ ë§¤ì¹­ ê°œìˆ˜ ê³„ì‚°
            df_matches = pd.read_sql_query("SELECT * FROM matches;", conn)
            match_avg = df_matches.shape[0] if not df_matches.empty else 0

        feature_data.append([db_path, param_list[itteration][0], param_list[itteration][1], param_list[itteration][2] , round(average_keypoints, 4)])
        itteration += 1

    # âœ… íŠ¹ì´ì  & ë§¤ì¹­ ê°œìˆ˜ CSV ì €ì¥
    feature_df = pd.DataFrame(feature_data, columns=["db_path", "num_octaves", "edge_threshold", "peak_threshold", "keypoint_avg"])
    feature_df.to_csv(feature_csv, index=False)

    print("âœ… Feature extraction completed successfully!")
